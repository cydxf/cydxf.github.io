当你第1次接触神经网络的时候，一定会觉得非常奇怪，这些线这些方框是什么东西啊，还有什么是输入输出隐藏层编制，沉重，还有激活函数损失函数。然后更不巧的是，如果你再看不懂这些情况下又去看的代码，你会发现更加的离谱，更加的抽象，完全不知道这个代码在干些什么，那么我当初也是和你完全一样，通过学习和理解之后呢，我发现其实原理是非常简单的，这里举一个简单的例子，让你也能快速理解，不妨先给视频点个免费的赞吧，那么在这张图上左侧呢是一个神经网络示意图，左侧是一个输入，x测试输出中间是一层一层，然后右侧呢是这个神经网络要干的事情，也就是说我们需要你和这个预估之外，是他与这个真实外重逢，首先需要解释一点是这个神经网络虽然名字叫神经网络，可他和我们生物上的神经网络除了名字和这个图画出来形式比较像以外，并没有其他什么共同点，至少。
生物的神经网络和我们这种机器学习用神经网络在底层原理上是完全不同的，所以作为初学者一定要知道这个神经网络呢，只是示意图长得像一个神经网络，我们看着像不像一个神经元，然后如果有很多收入的话就连起来就会形成交叉，看起来就像一张网络一样，所以它叫做神经网络，让我们看看在不谈神经网络的前提下，右边这个图正常人是如何拟合的，我们很容易发现上面这幅图呢，是不是就等于下面这三条直线进行相加呀？Y=1+2+3, 也就是说在这一点斜率进行了一个改变，然后在这一点呢，这两个相加之后，斜率是这是他，然后在这一点呢，这三者相加的协议呢是它也就是说只要把这三条折线加起来就得玩完，那我们现在假设这上面这条y的斜率分别是01-1和1，然后在012这三点发生了突变形成了一条直线，那么下面这三三个函数，斜率分别应该就是1-2和3，那么也没有什么。
函数可以方便的去表示这样的折线呢，那这时候我们就不得不提到一个函数叫做value函数，我们把它记作x，那这个函数长的就是这样的，就是在坐标轴左边的斜率是然后在原点斜率变为一，那知道这个函数之后是不是这三个函数就非常好表示了，首先呢，我们需要知道这个函数想要平移或缩放应该怎么办呢？比如我们想要x往右一格让它从一这边开始往上走，那是不是只要2括号x-1就行了？然后如果往左移就是括号x+1对不对？那么如何进行缩放呢？比如说我们要把它分成这样，斜率能变成原来两倍，也就是说把他往往外走着边几，那是不是就变成22x，那这个缩放呢是允许你任意的往里面挤，往里面挤的话，比如说RS这样呢它整个就会被拉过来，斜率变为原来两倍也允许你往外拉，比如说2/x，那这协议就会变缓，而且还允许你，比如说x那就是它的反方向。
也就是到这边来了，那有了平移和缩放，那是不是就意味着我们可以把这个转折点挪到任意一个位置，并且这条线斜率也是可以随意变化的，但是您没有发现有两个缺点，那就是这个点呢，它只能在x轴上动，它并不能往上走，也就是它只具有一个一个维度，它不能跑到其他地方，比如说我们想要一个这样的函数，那就不行，还有一个问题呢，其实这条线它始终是在上方的，因为你看这个原函数，无论你怎么样子放松，这条线始终在上方下方呢，是不可能用函数，那如果我们想要一个这样的函数，那显然是不可能的，所以还需要有其他的办法，那就其他办法实际上也很简单，我们看这个函数是不是就可以看成这样的一个函数往上平移类，那是不是就是在这个r什么什么东西外面加一个加一个东西其实就可以从这个到这个，那像这个呢，其实也非常简单，那就在前面加一个符号呗，对不对？那能把这样的这种形式x+b的这种操作叫做一个县。
进行操作，那我们这里也是对这个人流函数这个函数本身进行了一次现行操作，然后再看看前面这些，比如我们这个三里面是不是它等于22括号x-2，也就是括号2x-4，没有发现这个里面是对x先进行一次现行操作，也就是说对x进行一次线性操作，然后再进行一次二操作，然后再对这个输出呢，再进行一次线性操作，那就可以得到我们要的这个任意的这种形状形状的函数，那我们以一个流程图的形式来说明，对于一个数字x，我们先进行一个现行操作，比如我们这里面这个里面这个东西二括号x-1，然后再进行一个非线性操作啊，也就是他然后再进行一次线性操作，比如说我们这里选个符号，或者我们如果要把它往上下移的话，还需要加一个b，然后就得到一个任意位置的这种东西，那再看刚才这个123是不是都是属于任意位置的这种东西，那把它们加起来是不是就得到他呀？那我们现在再来看这个神器。
网络示意图是不是就恍然大悟了，只不过他这个写法和我们流程图的写法有所区别，他这样写是为了美观，所以可能会导致有些小白看不懂，我们对输入进行一次操作也就是一次线性操作呀，然后呢，再经过一个隐藏层神经元，实际上就是一个非线性操作啊，然后再经过一次线性操作就可以输出了，那他这一条输出呢，是不是就意味着这种东西，然后这条数呢是另外一个任意位置的这种东西，然后这条说说呢又是另外一个任意位置，这种东西它分别就对应着123，也就是说我们给你三个自由度，给你3三个任意位置这种东西要求你去把它加起来可以得到它，那么这个神经网络就是在城市这三个任意位置这种东西看看怎么挪怎么上下左右挪，然后调整斜率可以让它等于它，下面就来介绍一些小白可能不太懂的名词，首先什么是权重和偏置呢？我们刚才是不是提到一次线性操作就是对输入进行一个x+b的操作。
B呢就是把us偏置呢，就是权重位置，那这里呢，我们把鼠标放到任意条线上都可以看到，他说wait是什么，然后再放到这个点上呢，可以看到偏置是什么，那这两个加起来呢，其实就是对x的线性操作也就是WX+b，也跟我们刚才写的x+b是一样的，只不过神经网络里面肯定不能把它叫做什么斜率和截距，对吧，造成权重和偏置更有意义，然后什么是隐藏的隐藏层，就是中间这一层为什么叫隐藏层呢？因为它不体现在书上，也就是说你的输入并不是直接通过一个什么函数直接接到书上的，那么中间就需要经过这个隐藏层，实际经过，我们刚才提到其实可以发现这个书是可以直接写成输入的一种函数的，只不过这样非常的麻烦，而且实际过程中我们很难直接找到这样一个函数，比如说把1和1200+3直接写出来，其实就2x加这个加这个对不对？但是我们实际中不可能人去写出这样一种特殊函数形式，所以我们就需要。
隐藏的帮忙，如果你刚开始就直接写成这种形式，实际上就没有一条线拉过去，没有什么隐藏了对不对？然后呢就是激活函数是什么，你看到我们这个方框里面写了个这个啊，表示radio radio呢就是一种激活函数，奇偶函数呢必须是非线性的，我们可以看到这边有很多种激活函数，他这边也给出了一种线性的结构函数，使用新的激活函数，其实相当于没有什么激活作用，激活函数位置在这边，他为什么叫激活呢？也就是说使得前前面这个输入变得有效，我们知道神经网络大多是完成一种理想的非线性礼盒的任务重点在于非线性，因为如果是一种线性拟合的话，那一眼就看出来，根本用不着用神经网络这种工具，那既然是非线性的，如果你这个位置上仍然用一个线性函数好，那么最终结果一定是这样的，就是你前面先进行了线性操作，然后如果这边不是l的话，你又进行线性操作，然后再进行现金操作，实际上呢就相当于一次现金操作，你看这个函数我们永远可以直接把它画成一个。
X+b的这种格式对不对？你这么多参数实际上就相当于一次线性操作一条线直接拉过去，所以说我们今后函数一定不能选取一个线性函数，也就是说它这个激活函数自己要有一定的特征，比如像我们这边这个x，他就是说长得像这样，那么我们靠长的像这样的东西就能你和他对不对，如果是长得像一条线的，你无论怎么加怎么减的，他最终都是一条线对不对？但是如果长的像这样的，那你通过多个长的像这样的东西，你看就可以弄出他了，如果是三条线你怎么加他最终都是一条线，实际上也就是我这边说的这个，然后最后什么是损失函数呢，就看这个图就可以了，你看最后你和y是不是离这个真实之外有一定的差距，那么我们就需要创造一个损失函数来描述这个差距，通常在用一个最简单的均方误差来表示，也就是说这个值与真实值的差距的平方，然后这样加起来当然也可以是绝对值，然后我们通过调整这个线性和非线性操作的这些参数啊。
实际上只有4个，也就是这边这个现行操作有两个参数对吧，这边有两个参数，这个东西就是非线性操作是固定的没有参数，那总共这里面这边两个参数这边两个参数，总共有12个参数，我们调整了12个参数呢，最终使得这个损失函数最小，也就说y和y的差距越小，至于怎么调整，那就是等你先把这个看懂之后才能再说内容了，那么这就是人工智能神经网络和机器学习的基本原理，在我的粉丝群中就有一个人工智能聊天机器人，欢迎大家体验，那本期视频就到此为止了，如果你看懂的话就请给个三年吧，如果我没有看懂，欢迎在评论区进行补充和提问，谢谢大家。
